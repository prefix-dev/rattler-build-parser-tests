context:
  name: torchao
  version: "0.13.0"
  cutlass_version: "3.9.0"
  use_cuda: ${{ cuda_compiler_version != "None" }}
  cuda_build_string: cuda_${{ cuda_compiler_version | version_to_buildstring }}
  string_prefix: ${{ cuda_build_string if cuda_compiler_version != "None" else "cpu_" }}

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  - url: https://github.com/pytorch/ao/archive/refs/tags/v${{ version }}.tar.gz
    sha256: 3d2aac7c2dcc9bb7aabe5d9cf8bd508bac2b7e0e4582e162932bf4667a079d0c
  - url: https://github.com/NVIDIA/cutlass/archive/refs/tags/v${{ cutlass_version }}.tar.gz
    sha256: 0ea98a598d1f77fade5187ff6ec6d9e6ef3acd267ee68850aae6e800dcbd69c7
    target_directory: third_party/cutlass

build:
  number: 1
  string: ${{ string_prefix }}py${{ python | version_to_buildstring }}h${{ hash }}_${{ build_number }}
  skip:
    - win
    # - not use_cuda  # Until the CUDA build works
    # - match(python, "!=3.12")  # Until the build works

requirements:
  build:
    - if: build_platform != target_platform
      then:
        - python
        - cross-python_${{ target_platform }}
        - pytorch
        - if: use_cuda
          then:
            - cuda-cudart-dev
            - libcublas-dev
            - libcusolver-dev
            - libcusparse-dev
    - ${{ compiler('c') }}
    - ${{ compiler('cxx') }}
    - ${{ stdlib('c') }}
    - cmake <4.0.0,>=3.19.0
    - if: use_cuda
      then:
        - ${{ compiler('cuda') }}
        - cuda-version ==${{ cuda_compiler_version }}
        - ninja
  host:
    - python
    - pip
    - setuptools
    - if: use_cuda
      then:
        - cuda-version ==${{ cuda_compiler_version }}
        - cuda-cudart-dev
        - libcublas-dev
        - libcusolver-dev
        - libcusparse-dev
        - pytorch * [build=cuda*]
      else:
        - pytorch * [build=cpu*]
  run:
    - python
    # Indirectly needed through torch/distributed/elastic/rendezvous/registry.py
    # Happens when importing torchao
    - importlib-metadata
    - if: use_cuda
      then:
        - pytorch * [build=cuda*]
      else:
        - pytorch * [build=cpu*]

  ignore_run_exports:
    from_package:
      - if: use_cuda
        then:
          - libcublas-dev
          - libcusolver-dev
          - libcusparse-dev

tests:
  - python:
      imports:
        - torchao
      pip_check: true

about:
  homepage: https://pytorch.org/ao/stable/index.html
  summary: PyTorch native quantization and sparsity for training and inference
  description: |
    TorchAO is a PyTorch-native model optimization framework leveraging quantization
    and sparsity to provide an end-to-end, training-to-serving workflow for
    AI models. TorchAO works out-of-the-box with torch.compile() and FSDP2
    across most HuggingFace PyTorch models.
  license: BSD-3-Clause
  license_file:
    - LICENSE
    - third_party/cutlass/LICENSE.txt
  documentation: https://docs.pytorch.org/ao/stable/
  repository: https://github.com/pytorch/ao

extra:
  recipe-maintainers:
    - shermansiu
    - isuruf
