context:
  name: apache-airflow-providers-databricks
  version: "7.8.3"

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/apache_airflow_providers_databricks-${{ version }}.tar.gz
  sha256: a94f913472d51599f1f6d7e718f32839aff3e2f11a1aedf9822e7b781665c426

build:
  noarch: python
  script: python -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python ${{ python_min }}.*
    - pip
    - flit-core ==3.12.0
  run:
    - python >=${{ python_min }}
    - apache-airflow >=2.11.0
    - apache-airflow-providers-common-compat >=1.12.0
    - apache-airflow-providers-common-sql >=1.27.0
    - requests >=2.32.0,<3
    - databricks-sql-connector >=4.0.0
    - aiohttp >=3.9.2,<4
    - mergedeep >=1.3.4
    # more restrictive for python >=3.13
    - pandas >=2.2.3
    # more restrictive for python >=3.13
    - pyarrow >=18.0.0

tests:
  - python:
      imports:
        - airflow.providers.databricks
      pip_check: true
      python_version: ${{ python_min }}.*

about:
  homepage: https://github.com/apache/airflow/
  summary: Provider package apache-airflow-providers-databricks for Apache Airflow
  license: Apache-2.0
  license_file:
    - LICENSE
    - NOTICE
  documentation: https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html
  repository: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
