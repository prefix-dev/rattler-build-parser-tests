[
  {
    "build_configuration": {
      "build_platform": {
        "platform": "linux-64",
        "virtual_packages": [
          "__unix=0=0",
          "__linux=6.6.87.2=0",
          "__glibc=2.35=0",
          "__cuda=13.0=0",
          "__archspec=1=x86_64_v4"
        ]
      },
      "channel_priority": "strict",
      "channels": [
        "https://conda.anaconda.org/conda-forge"
      ],
      "directories": {
        "build_dir": "/home/wolfv/Programs/rattler-build/output/bld/rattler-build_colt5-attention",
        "build_prefix": "/home/wolfv/Programs/rattler-build/output/bld/rattler-build_colt5-attention/build_env",
        "host_prefix": "/home/wolfv/Programs/rattler-build/output/bld/rattler-build_colt5-attention/host_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_",
        "work_dir": "/home/wolfv/Programs/rattler-build/output/bld/rattler-build_colt5-attention/work"
      },
      "hash": {
        "hash": "cf101f3",
        "prefix": "py"
      },
      "host_platform": {
        "platform": "linux-64",
        "virtual_packages": [
          "__unix=0=0",
          "__linux=6.6.87.2=0",
          "__glibc=2.35=0",
          "__cuda=13.0=0",
          "__archspec=1=x86_64_v4"
        ]
      },
      "packaging_settings": {
        "archive_type": "conda",
        "compression_level": 15
      },
      "solve_strategy": "highest",
      "subpackages": {
        "colt5-attention": {
          "build_string": "pyhcf101f3_1",
          "name": "colt5-attention",
          "version": "0.11.1"
        }
      },
      "target_platform": "noarch",
      "timestamp": "2025-12-12T16:19:26.689138028Z",
      "variant": {
        "channel_sources": "conda-forge",
        "channel_targets": "conda-forge main",
        "python_min": "3.10",
        "target_platform": "noarch"
      }
    },
    "extra_meta": {},
    "finalized_dependencies": null,
    "finalized_sources": null,
    "recipe": {
      "about": {
        "homepage": "https://github.com/lucidrains/CoLT5-attention",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "summary": "Implementation of the conditionally routed attention in the CoLT5 architecture, in Pytorch"
      },
      "build": {
        "noarch": "python",
        "number": 1,
        "script": "${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation",
        "string": "pyhcf101f3_1"
      },
      "context": {
        "version": "0.11.1"
      },
      "extra": {
        "recipe-maintainers": [
          "danielnachun"
        ]
      },
      "package": {
        "name": "colt5-attention",
        "version": "0.11.1"
      },
      "requirements": {
        "host": [
          "python 3.10.*",
          "pip",
          "setuptools"
        ],
        "run": [
          "python >=3.10",
          "einops >=0.8.0",
          "local-attention >=1.8.6",
          "packaging",
          "pytorch >=1.10"
        ]
      },
      "schema_version": 1,
      "source": [
        {
          "sha256": "597f1e4af5b9006d8969d73905ea03fcc55945cfb0ab7d3d722fd05fff6322f6",
          "url": "https://github.com/lucidrains/colt5-attention/archive/0.11.1.tar.gz"
        }
      ],
      "tests": [
        {
          "python": {
            "imports": [
              "colt5_attention"
            ]
          }
        },
        {
          "requirements": {
            "run": [
              "pip",
              "python 3.10.*"
            ]
          },
          "script": "pip check"
        }
      ]
    },
    "system_tools": {
      "rattler-build": "0.51.0"
    }
  }
]